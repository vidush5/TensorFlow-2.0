{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  ...  worst concave points  worst symmetry  worst fractal dimension\n",
       "0        17.99         10.38          122.80  ...                0.2654          0.4601                  0.11890\n",
       "1        20.57         17.77          132.90  ...                0.1860          0.2750                  0.08902\n",
       "2        19.69         21.25          130.00  ...                0.2430          0.3613                  0.08758\n",
       "3        11.42         20.38           77.58  ...                0.2575          0.6638                  0.17300\n",
       "4        20.29         14.34          135.10  ...                0.1625          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data = cancer_data.data, columns = cancer_data.feature_names )\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cancer_data.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standerdizing the dataset\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26670379,  0.64119581,  0.21021862, ...,  0.57195757,\n",
       "        -0.36743271, -0.29487344],\n",
       "       [-1.50538429, -0.78076949, -1.4608281 , ..., -0.14909852,\n",
       "         0.04677597,  1.00205472],\n",
       "       [ 1.50388483,  2.19180417,  1.67631803, ...,  1.18936185,\n",
       "        -0.13144928,  0.93430053],\n",
       "       ...,\n",
       "       [-0.30323355,  0.01865526, -0.38082036, ..., -1.55951427,\n",
       "        -0.75688789, -1.18922878],\n",
       "       [-0.07525861, -0.69347598, -0.14238757, ..., -0.89178629,\n",
       "        -0.88395589, -0.72398332],\n",
       "       [-0.63963558, -0.12147379, -0.56963008, ...,  0.59599277,\n",
       "         3.07495497,  3.17583505]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08915952,  1.20860361,  0.01132291, ...,  0.55843777,\n",
       "         1.24319547,  1.93932104],\n",
       "       [ 2.26009436,  0.10135438,  2.45092202, ...,  2.64499382,\n",
       "         1.90988992,  0.78693516],\n",
       "       [ 0.08599195,  0.22770024,  0.09846586, ...,  1.03463523,\n",
       "         3.0617531 ,  0.97946999],\n",
       "       ...,\n",
       "       [-1.22597599, -0.89333217, -1.14049708, ...,  0.63354778,\n",
       "         0.34711852,  2.36843093],\n",
       "       [-0.35327682,  0.07149081, -0.37839972, ..., -0.76740411,\n",
       "         0.68541644, -0.37279076],\n",
       "       [-0.64797613, -0.42240667, -0.67694501, ..., -1.07956131,\n",
       "         0.49894003, -1.02718333]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(455, 30, 1)\n",
    "X_test = X_test.reshape(114, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2,activation='relu', input_shape = (30,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=2,activation='relu', input_shape = (30,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=2,activation='relu', input_shape = (30,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 29, 32)            96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 29, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 28, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 27, 128)           16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 128)           512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3457      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 25,121\n",
      "Trainable params: 24,673\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0005),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/500\n",
      "455/455 [==============================] - 0s 501us/sample - loss: 5.2248 - accuracy: 0.6571 - val_loss: 0.8401 - val_accuracy: 0.9386\n",
      "Epoch 2/500\n",
      "455/455 [==============================] - 0s 516us/sample - loss: 5.1910 - accuracy: 0.6593 - val_loss: 0.8348 - val_accuracy: 0.9386\n",
      "Epoch 3/500\n",
      "455/455 [==============================] - 0s 518us/sample - loss: 5.6268 - accuracy: 0.6352 - val_loss: 0.8322 - val_accuracy: 0.9386\n",
      "Epoch 4/500\n",
      "455/455 [==============================] - 0s 508us/sample - loss: 5.5329 - accuracy: 0.6396 - val_loss: 0.8294 - val_accuracy: 0.9386\n",
      "Epoch 5/500\n",
      "455/455 [==============================] - 0s 598us/sample - loss: 5.4316 - accuracy: 0.6418 - val_loss: 0.8380 - val_accuracy: 0.9298\n",
      "Epoch 6/500\n",
      "455/455 [==============================] - 0s 571us/sample - loss: 5.3593 - accuracy: 0.6505 - val_loss: 0.8383 - val_accuracy: 0.9298\n",
      "Epoch 7/500\n",
      "455/455 [==============================] - 0s 617us/sample - loss: 5.1218 - accuracy: 0.6659 - val_loss: 0.8419 - val_accuracy: 0.9298\n",
      "Epoch 8/500\n",
      "455/455 [==============================] - 0s 773us/sample - loss: 4.9195 - accuracy: 0.6791 - val_loss: 0.7358 - val_accuracy: 0.9298\n",
      "Epoch 9/500\n",
      "455/455 [==============================] - 0s 690us/sample - loss: 5.0204 - accuracy: 0.6725 - val_loss: 0.7297 - val_accuracy: 0.9298\n",
      "Epoch 10/500\n",
      "455/455 [==============================] - 0s 725us/sample - loss: 5.0676 - accuracy: 0.6659 - val_loss: 1.0792 - val_accuracy: 0.9298\n",
      "Epoch 11/500\n",
      "455/455 [==============================] - 0s 847us/sample - loss: 5.2402 - accuracy: 0.6505 - val_loss: 0.9447 - val_accuracy: 0.9386\n",
      "Epoch 12/500\n",
      "455/455 [==============================] - 0s 916us/sample - loss: 5.5635 - accuracy: 0.6374 - val_loss: 0.9439 - val_accuracy: 0.9386\n",
      "Epoch 13/500\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 5.5610 - accuracy: 0.6374 - val_loss: 0.8392 - val_accuracy: 0.9386\n",
      "Epoch 14/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 5.5273 - accuracy: 0.6396 - val_loss: 0.8407 - val_accuracy: 0.9386\n",
      "Epoch 15/500\n",
      "455/455 [==============================] - 0s 497us/sample - loss: 4.9501 - accuracy: 0.6791 - val_loss: 0.8434 - val_accuracy: 0.9386\n",
      "Epoch 16/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 5.1911 - accuracy: 0.6615 - val_loss: 0.8368 - val_accuracy: 0.9386\n",
      "Epoch 17/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.4918 - accuracy: 0.6440 - val_loss: 0.8314 - val_accuracy: 0.9386\n",
      "Epoch 18/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9875 - accuracy: 0.6747 - val_loss: 0.8411 - val_accuracy: 0.9386\n",
      "Epoch 19/500\n",
      "455/455 [==============================] - 0s 466us/sample - loss: 5.2592 - accuracy: 0.6571 - val_loss: 0.9461 - val_accuracy: 0.9386\n",
      "Epoch 20/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9508 - accuracy: 0.6769 - val_loss: 0.9486 - val_accuracy: 0.9386\n",
      "Epoch 21/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3243 - accuracy: 0.6549 - val_loss: 0.9483 - val_accuracy: 0.9386\n",
      "Epoch 22/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 5.4607 - accuracy: 0.6440 - val_loss: 0.9496 - val_accuracy: 0.9386\n",
      "Epoch 23/500\n",
      "455/455 [==============================] - 0s 554us/sample - loss: 5.0863 - accuracy: 0.6681 - val_loss: 0.9499 - val_accuracy: 0.9386\n",
      "Epoch 24/500\n",
      "455/455 [==============================] - 0s 440us/sample - loss: 4.6793 - accuracy: 0.6967 - val_loss: 0.9499 - val_accuracy: 0.9386\n",
      "Epoch 25/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 4.9326 - accuracy: 0.6725 - val_loss: 0.8167 - val_accuracy: 0.9386\n",
      "Epoch 26/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.1202 - accuracy: 0.6659 - val_loss: 0.8134 - val_accuracy: 0.9474\n",
      "Epoch 27/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.0186 - accuracy: 0.6747 - val_loss: 0.8121 - val_accuracy: 0.9474\n",
      "Epoch 28/500\n",
      "455/455 [==============================] - 0s 475us/sample - loss: 4.5113 - accuracy: 0.7077 - val_loss: 0.7378 - val_accuracy: 0.9474\n",
      "Epoch 29/500\n",
      "455/455 [==============================] - 0s 440us/sample - loss: 5.2607 - accuracy: 0.6549 - val_loss: 0.7079 - val_accuracy: 0.9474\n",
      "Epoch 30/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.6627 - accuracy: 0.6308 - val_loss: 0.5861 - val_accuracy: 0.9474\n",
      "Epoch 31/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.4285 - accuracy: 0.6440 - val_loss: 0.4627 - val_accuracy: 0.9474\n",
      "Epoch 32/500\n",
      "455/455 [==============================] - 0s 475us/sample - loss: 5.2552 - accuracy: 0.6593 - val_loss: 0.4410 - val_accuracy: 0.9474\n",
      "Epoch 33/500\n",
      "455/455 [==============================] - 0s 469us/sample - loss: 5.1225 - accuracy: 0.6659 - val_loss: 0.4631 - val_accuracy: 0.9474\n",
      "Epoch 34/500\n",
      "455/455 [==============================] - 0s 408us/sample - loss: 5.4566 - accuracy: 0.6462 - val_loss: 0.5533 - val_accuracy: 0.9474\n",
      "Epoch 35/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.2988 - accuracy: 0.6505 - val_loss: 0.5499 - val_accuracy: 0.9649\n",
      "Epoch 36/500\n",
      "455/455 [==============================] - 0s 455us/sample - loss: 5.1929 - accuracy: 0.6593 - val_loss: 0.6733 - val_accuracy: 0.9561\n",
      "Epoch 37/500\n",
      "455/455 [==============================] - 0s 676us/sample - loss: 5.3921 - accuracy: 0.6484 - val_loss: 0.6733 - val_accuracy: 0.9561\n",
      "Epoch 38/500\n",
      "455/455 [==============================] - 0s 664us/sample - loss: 5.1222 - accuracy: 0.6659 - val_loss: 0.6733 - val_accuracy: 0.9561\n",
      "Epoch 39/500\n",
      "455/455 [==============================] - 0s 578us/sample - loss: 4.8493 - accuracy: 0.6857 - val_loss: 0.6733 - val_accuracy: 0.9561\n",
      "Epoch 40/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.0944 - accuracy: 0.6681 - val_loss: 0.5637 - val_accuracy: 0.9474\n",
      "Epoch 41/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.5597 - accuracy: 0.6396 - val_loss: 0.5699 - val_accuracy: 0.9561\n",
      "Epoch 42/500\n",
      "455/455 [==============================] - 0s 440us/sample - loss: 5.5295 - accuracy: 0.6374 - val_loss: 0.5715 - val_accuracy: 0.9474\n",
      "Epoch 43/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.1865 - accuracy: 0.6637 - val_loss: 0.5761 - val_accuracy: 0.9474\n",
      "Epoch 44/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.5415 - accuracy: 0.6352 - val_loss: 0.5672 - val_accuracy: 0.9561\n",
      "Epoch 45/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.1914 - accuracy: 0.6615 - val_loss: 0.4429 - val_accuracy: 0.9561\n",
      "Epoch 46/500\n",
      "455/455 [==============================] - 0s 475us/sample - loss: 4.6459 - accuracy: 0.6989 - val_loss: 0.4536 - val_accuracy: 0.9561\n",
      "Epoch 47/500\n",
      "455/455 [==============================] - 0s 440us/sample - loss: 5.3242 - accuracy: 0.6527 - val_loss: 0.5616 - val_accuracy: 0.9474\n",
      "Epoch 48/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.2908 - accuracy: 0.6549 - val_loss: 0.5605 - val_accuracy: 0.9561\n",
      "Epoch 49/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.1539 - accuracy: 0.6659 - val_loss: 0.5578 - val_accuracy: 0.9561\n",
      "Epoch 50/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.4691 - accuracy: 0.6396 - val_loss: 0.5622 - val_accuracy: 0.9561\n",
      "Epoch 51/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.5594 - accuracy: 0.6396 - val_loss: 0.5624 - val_accuracy: 0.9561\n",
      "Epoch 52/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.2584 - accuracy: 0.6571 - val_loss: 0.5576 - val_accuracy: 0.9561\n",
      "Epoch 53/500\n",
      "455/455 [==============================] - 0s 475us/sample - loss: 4.4065 - accuracy: 0.7143 - val_loss: 0.5560 - val_accuracy: 0.9561\n",
      "Epoch 54/500\n",
      "455/455 [==============================] - 0s 475us/sample - loss: 4.8645 - accuracy: 0.6813 - val_loss: 0.8426 - val_accuracy: 0.9298\n",
      "Epoch 55/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.1242 - accuracy: 0.6637 - val_loss: 1.6584 - val_accuracy: 0.8860\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 475us/sample - loss: 5.4394 - accuracy: 0.6418 - val_loss: 1.7582 - val_accuracy: 0.8860\n",
      "Epoch 57/500\n",
      "455/455 [==============================] - 0s 535us/sample - loss: 5.6318 - accuracy: 0.6330 - val_loss: 1.7582 - val_accuracy: 0.8860\n",
      "Epoch 58/500\n",
      "455/455 [==============================] - 0s 512us/sample - loss: 5.5646 - accuracy: 0.6374 - val_loss: 1.6730 - val_accuracy: 0.8860\n",
      "Epoch 59/500\n",
      "455/455 [==============================] - 0s 447us/sample - loss: 5.2200 - accuracy: 0.6615 - val_loss: 1.7582 - val_accuracy: 0.8860\n",
      "Epoch 60/500\n",
      "455/455 [==============================] - 0s 441us/sample - loss: 5.6736 - accuracy: 0.6286 - val_loss: 1.6356 - val_accuracy: 0.8860\n",
      "Epoch 61/500\n",
      "455/455 [==============================] - 0s 552us/sample - loss: 5.1213 - accuracy: 0.6659 - val_loss: 1.4000 - val_accuracy: 0.8947\n",
      "Epoch 62/500\n",
      "455/455 [==============================] - 0s 838us/sample - loss: 5.8311 - accuracy: 0.6220 - val_loss: 1.3872 - val_accuracy: 0.8947\n",
      "Epoch 63/500\n",
      "455/455 [==============================] - 0s 953us/sample - loss: 5.3585 - accuracy: 0.6505 - val_loss: 1.3825 - val_accuracy: 0.8947\n",
      "Epoch 64/500\n",
      "455/455 [==============================] - 0s 982us/sample - loss: 5.5617 - accuracy: 0.6374 - val_loss: 1.3786 - val_accuracy: 0.8947\n",
      "Epoch 65/500\n",
      "455/455 [==============================] - 0s 633us/sample - loss: 5.8662 - accuracy: 0.6176 - val_loss: 1.3772 - val_accuracy: 0.8947\n",
      "Epoch 66/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 5.3273 - accuracy: 0.6527 - val_loss: 1.3761 - val_accuracy: 0.8947\n",
      "Epoch 67/500\n",
      "455/455 [==============================] - 0s 480us/sample - loss: 5.3901 - accuracy: 0.6505 - val_loss: 1.3758 - val_accuracy: 0.8860\n",
      "Epoch 68/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.8379 - accuracy: 0.6176 - val_loss: 1.3705 - val_accuracy: 0.9035\n",
      "Epoch 69/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 5.3576 - accuracy: 0.6505 - val_loss: 1.3686 - val_accuracy: 0.9035\n",
      "Epoch 70/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 6.0068 - accuracy: 0.6066 - val_loss: 1.2703 - val_accuracy: 0.9035\n",
      "Epoch 71/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3255 - accuracy: 0.6527 - val_loss: 1.1223 - val_accuracy: 0.9035\n",
      "Epoch 72/500\n",
      "455/455 [==============================] - 0s 579us/sample - loss: 5.8670 - accuracy: 0.6176 - val_loss: 1.1104 - val_accuracy: 0.9035\n",
      "Epoch 73/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.3913 - accuracy: 0.6505 - val_loss: 1.1076 - val_accuracy: 0.9035\n",
      "Epoch 74/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.0167 - accuracy: 0.6747 - val_loss: 1.1069 - val_accuracy: 0.9123\n",
      "Epoch 75/500\n",
      "455/455 [==============================] - 0s 659us/sample - loss: 5.4633 - accuracy: 0.6440 - val_loss: 1.1121 - val_accuracy: 0.9123\n",
      "Epoch 76/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.8317 - accuracy: 0.6220 - val_loss: 1.1170 - val_accuracy: 0.9035\n",
      "Epoch 77/500\n",
      "455/455 [==============================] - 0s 578us/sample - loss: 5.6778 - accuracy: 0.6286 - val_loss: 1.0950 - val_accuracy: 0.9211\n",
      "Epoch 78/500\n",
      "455/455 [==============================] - 0s 429us/sample - loss: 4.9167 - accuracy: 0.6813 - val_loss: 1.1004 - val_accuracy: 0.9123\n",
      "Epoch 79/500\n",
      "455/455 [==============================] - 0s 414us/sample - loss: 5.5261 - accuracy: 0.6418 - val_loss: 1.1082 - val_accuracy: 0.9123\n",
      "Epoch 80/500\n",
      "455/455 [==============================] - 0s 525us/sample - loss: 5.1013 - accuracy: 0.6659 - val_loss: 0.8259 - val_accuracy: 0.9386\n",
      "Epoch 81/500\n",
      "455/455 [==============================] - 0s 516us/sample - loss: 5.3934 - accuracy: 0.6484 - val_loss: 0.8195 - val_accuracy: 0.9386\n",
      "Epoch 82/500\n",
      "455/455 [==============================] - 0s 739us/sample - loss: 4.6093 - accuracy: 0.7011 - val_loss: 0.9603 - val_accuracy: 0.9298\n",
      "Epoch 83/500\n",
      "455/455 [==============================] - 1s 2ms/sample - loss: 4.9219 - accuracy: 0.6769 - val_loss: 0.9556 - val_accuracy: 0.9298\n",
      "Epoch 84/500\n",
      "455/455 [==============================] - 0s 899us/sample - loss: 4.8538 - accuracy: 0.6835 - val_loss: 0.9474 - val_accuracy: 0.9386\n",
      "Epoch 85/500\n",
      "455/455 [==============================] - 0s 894us/sample - loss: 4.5892 - accuracy: 0.6989 - val_loss: 0.6789 - val_accuracy: 0.9561\n",
      "Epoch 86/500\n",
      "455/455 [==============================] - 1s 2ms/sample - loss: 5.0190 - accuracy: 0.6725 - val_loss: 0.6767 - val_accuracy: 0.9561\n",
      "Epoch 87/500\n",
      "455/455 [==============================] - 1s 1ms/sample - loss: 5.4574 - accuracy: 0.6462 - val_loss: 0.6771 - val_accuracy: 0.9561\n",
      "Epoch 88/500\n",
      "455/455 [==============================] - 0s 976us/sample - loss: 5.1552 - accuracy: 0.6637 - val_loss: 0.6796 - val_accuracy: 0.9561\n",
      "Epoch 89/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.0845 - accuracy: 0.6703 - val_loss: 0.5885 - val_accuracy: 0.9561\n",
      "Epoch 90/500\n",
      "455/455 [==============================] - 0s 576us/sample - loss: 5.1543 - accuracy: 0.6659 - val_loss: 0.5736 - val_accuracy: 0.9561\n",
      "Epoch 91/500\n",
      "455/455 [==============================] - 0s 549us/sample - loss: 4.9138 - accuracy: 0.6813 - val_loss: 0.5751 - val_accuracy: 0.9561\n",
      "Epoch 92/500\n",
      "455/455 [==============================] - 0s 582us/sample - loss: 5.2958 - accuracy: 0.6527 - val_loss: 0.6778 - val_accuracy: 0.9561\n",
      "Epoch 93/500\n",
      "455/455 [==============================] - 0s 828us/sample - loss: 5.3223 - accuracy: 0.6549 - val_loss: 0.6763 - val_accuracy: 0.9561\n",
      "Epoch 94/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.0523 - accuracy: 0.6703 - val_loss: 0.6769 - val_accuracy: 0.9561\n",
      "Epoch 95/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 4.9509 - accuracy: 0.6769 - val_loss: 0.6783 - val_accuracy: 0.9561\n",
      "Epoch 96/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.0849 - accuracy: 0.6703 - val_loss: 0.6785 - val_accuracy: 0.9561\n",
      "Epoch 97/500\n",
      "455/455 [==============================] - 0s 573us/sample - loss: 5.0887 - accuracy: 0.6681 - val_loss: 0.6833 - val_accuracy: 0.9474\n",
      "Epoch 98/500\n",
      "455/455 [==============================] - 0s 449us/sample - loss: 4.7846 - accuracy: 0.6879 - val_loss: 0.5733 - val_accuracy: 0.9474\n",
      "Epoch 99/500\n",
      "455/455 [==============================] - 0s 430us/sample - loss: 4.9152 - accuracy: 0.6813 - val_loss: 0.6833 - val_accuracy: 0.9474\n",
      "Epoch 100/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.1581 - accuracy: 0.6615 - val_loss: 0.5797 - val_accuracy: 0.9474\n",
      "Epoch 101/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9557 - accuracy: 0.6769 - val_loss: 0.5608 - val_accuracy: 0.9474\n",
      "Epoch 102/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.0506 - accuracy: 0.6725 - val_loss: 0.5648 - val_accuracy: 0.9561\n",
      "Epoch 103/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.7507 - accuracy: 0.6879 - val_loss: 0.5536 - val_accuracy: 0.9561\n",
      "Epoch 104/500\n",
      "455/455 [==============================] - 0s 437us/sample - loss: 4.8151 - accuracy: 0.6879 - val_loss: 0.5513 - val_accuracy: 0.9561\n",
      "Epoch 105/500\n",
      "455/455 [==============================] - 0s 670us/sample - loss: 5.4922 - accuracy: 0.6440 - val_loss: 0.5509 - val_accuracy: 0.9561\n",
      "Epoch 106/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.0233 - accuracy: 0.6703 - val_loss: 0.5457 - val_accuracy: 0.9649\n",
      "Epoch 107/500\n",
      "455/455 [==============================] - 0s 996us/sample - loss: 4.7536 - accuracy: 0.6901 - val_loss: 0.5437 - val_accuracy: 0.9649\n",
      "Epoch 108/500\n",
      "455/455 [==============================] - 0s 755us/sample - loss: 4.8221 - accuracy: 0.6813 - val_loss: 0.5431 - val_accuracy: 0.9649\n",
      "Epoch 109/500\n",
      "455/455 [==============================] - 0s 478us/sample - loss: 4.8132 - accuracy: 0.6879 - val_loss: 0.5418 - val_accuracy: 0.9649\n",
      "Epoch 110/500\n",
      "455/455 [==============================] - 0s 436us/sample - loss: 4.7481 - accuracy: 0.6901 - val_loss: 0.5410 - val_accuracy: 0.9649\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 412us/sample - loss: 5.2555 - accuracy: 0.6571 - val_loss: 0.5411 - val_accuracy: 0.9649\n",
      "Epoch 112/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.7794 - accuracy: 0.6901 - val_loss: 0.5414 - val_accuracy: 0.9649\n",
      "Epoch 113/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9906 - accuracy: 0.6747 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 114/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.2316 - accuracy: 0.6571 - val_loss: 0.2948 - val_accuracy: 0.9649\n",
      "Epoch 115/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3202 - accuracy: 0.6549 - val_loss: 0.5428 - val_accuracy: 0.9649\n",
      "Epoch 116/500\n",
      "455/455 [==============================] - 0s 489us/sample - loss: 5.3258 - accuracy: 0.6527 - val_loss: 0.5410 - val_accuracy: 0.9649\n",
      "Epoch 117/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 5.1513 - accuracy: 0.6659 - val_loss: 0.5402 - val_accuracy: 0.9649\n",
      "Epoch 118/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 4.9836 - accuracy: 0.6769 - val_loss: 0.5401 - val_accuracy: 0.9649\n",
      "Epoch 119/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 5.0857 - accuracy: 0.6681 - val_loss: 0.5401 - val_accuracy: 0.9649\n",
      "Epoch 120/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 4.7827 - accuracy: 0.6879 - val_loss: 0.5413 - val_accuracy: 0.9649\n",
      "Epoch 121/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 4.8132 - accuracy: 0.6879 - val_loss: 0.5408 - val_accuracy: 0.9649\n",
      "Epoch 122/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.1893 - accuracy: 0.6615 - val_loss: 0.5410 - val_accuracy: 0.9649\n",
      "Epoch 123/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.8143 - accuracy: 0.6879 - val_loss: 0.5422 - val_accuracy: 0.9649\n",
      "Epoch 124/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 5.0866 - accuracy: 0.6681 - val_loss: 0.5408 - val_accuracy: 0.9649\n",
      "Epoch 125/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.0831 - accuracy: 0.6703 - val_loss: 0.5400 - val_accuracy: 0.9649\n",
      "Epoch 126/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9251 - accuracy: 0.6747 - val_loss: 0.5405 - val_accuracy: 0.9649\n",
      "Epoch 127/500\n",
      "455/455 [==============================] - 0s 431us/sample - loss: 5.2253 - accuracy: 0.6571 - val_loss: 0.5395 - val_accuracy: 0.9649\n",
      "Epoch 128/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 4.2775 - accuracy: 0.7187 - val_loss: 0.5397 - val_accuracy: 0.9649\n",
      "Epoch 129/500\n",
      "455/455 [==============================] - 0s 626us/sample - loss: 4.8878 - accuracy: 0.6813 - val_loss: 0.5512 - val_accuracy: 0.9561\n",
      "Epoch 130/500\n",
      "455/455 [==============================] - 0s 961us/sample - loss: 4.5770 - accuracy: 0.7033 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 131/500\n",
      "455/455 [==============================] - 0s 961us/sample - loss: 4.7802 - accuracy: 0.6901 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 132/500\n",
      "455/455 [==============================] - 0s 790us/sample - loss: 5.1230 - accuracy: 0.6659 - val_loss: 0.5698 - val_accuracy: 0.9561\n",
      "Epoch 133/500\n",
      "455/455 [==============================] - 0s 591us/sample - loss: 4.8519 - accuracy: 0.6835 - val_loss: 0.5548 - val_accuracy: 0.9561\n",
      "Epoch 134/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3600 - accuracy: 0.6505 - val_loss: 0.5497 - val_accuracy: 0.9561\n",
      "Epoch 135/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.4063 - accuracy: 0.7143 - val_loss: 0.5506 - val_accuracy: 0.9561\n",
      "Epoch 136/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.7480 - accuracy: 0.6901 - val_loss: 0.5527 - val_accuracy: 0.9561\n",
      "Epoch 137/500\n",
      "455/455 [==============================] - 0s 455us/sample - loss: 5.2873 - accuracy: 0.6571 - val_loss: 0.5527 - val_accuracy: 0.9561\n",
      "Epoch 138/500\n",
      "455/455 [==============================] - 0s 453us/sample - loss: 5.1534 - accuracy: 0.6659 - val_loss: 0.5521 - val_accuracy: 0.9561\n",
      "Epoch 139/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9501 - accuracy: 0.6791 - val_loss: 0.5528 - val_accuracy: 0.9561\n",
      "Epoch 140/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.2562 - accuracy: 0.6571 - val_loss: 0.5540 - val_accuracy: 0.9561\n",
      "Epoch 141/500\n",
      "455/455 [==============================] - 0s 593us/sample - loss: 5.9316 - accuracy: 0.6154 - val_loss: 0.5626 - val_accuracy: 0.9561\n",
      "Epoch 142/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.0847 - accuracy: 0.6703 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 143/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 4.8133 - accuracy: 0.6879 - val_loss: 0.5677 - val_accuracy: 0.9561\n",
      "Epoch 144/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 5.1254 - accuracy: 0.6615 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 145/500\n",
      "455/455 [==============================] - 0s 673us/sample - loss: 5.1882 - accuracy: 0.6615 - val_loss: 0.5901 - val_accuracy: 0.9561\n",
      "Epoch 146/500\n",
      "455/455 [==============================] - 0s 562us/sample - loss: 5.4629 - accuracy: 0.6440 - val_loss: 0.5489 - val_accuracy: 0.9561\n",
      "Epoch 147/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 4.5419 - accuracy: 0.7055 - val_loss: 0.5445 - val_accuracy: 0.9649\n",
      "Epoch 148/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.5871 - accuracy: 0.6967 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 149/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.4239 - accuracy: 0.6484 - val_loss: 0.4285 - val_accuracy: 0.9649\n",
      "Epoch 150/500\n",
      "455/455 [==============================] - 0s 437us/sample - loss: 4.8879 - accuracy: 0.6791 - val_loss: 0.4195 - val_accuracy: 0.9649\n",
      "Epoch 151/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.0857 - accuracy: 0.6703 - val_loss: 0.4177 - val_accuracy: 0.9649\n",
      "Epoch 152/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.6282 - accuracy: 0.6330 - val_loss: 0.4176 - val_accuracy: 0.9649\n",
      "Epoch 153/500\n",
      "455/455 [==============================] - 0s 590us/sample - loss: 5.4239 - accuracy: 0.6484 - val_loss: 0.4182 - val_accuracy: 0.9649\n",
      "Epoch 154/500\n",
      "455/455 [==============================] - 0s 996us/sample - loss: 4.9148 - accuracy: 0.6813 - val_loss: 0.4162 - val_accuracy: 0.9649\n",
      "Epoch 155/500\n",
      "455/455 [==============================] - 0s 961us/sample - loss: 5.5061 - accuracy: 0.6396 - val_loss: 0.4065 - val_accuracy: 0.9737\n",
      "Epoch 156/500\n",
      "455/455 [==============================] - 0s 687us/sample - loss: 4.4758 - accuracy: 0.7099 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 157/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.3308 - accuracy: 0.6484 - val_loss: 0.4051 - val_accuracy: 0.9737\n",
      "Epoch 158/500\n",
      "455/455 [==============================] - 0s 478us/sample - loss: 4.3751 - accuracy: 0.7143 - val_loss: 0.4098 - val_accuracy: 0.9737\n",
      "Epoch 159/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.7104 - accuracy: 0.6945 - val_loss: 0.4129 - val_accuracy: 0.9649\n",
      "Epoch 160/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.2655 - accuracy: 0.6549 - val_loss: 0.4108 - val_accuracy: 0.9649\n",
      "Epoch 161/500\n",
      "455/455 [==============================] - 0s 439us/sample - loss: 5.4225 - accuracy: 0.6484 - val_loss: 0.5448 - val_accuracy: 0.9649\n",
      "Epoch 162/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.6802 - accuracy: 0.6967 - val_loss: 0.5499 - val_accuracy: 0.9649\n",
      "Epoch 163/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.0926 - accuracy: 0.6659 - val_loss: 0.4219 - val_accuracy: 0.9649\n",
      "Epoch 164/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 4.9502 - accuracy: 0.6791 - val_loss: 0.4177 - val_accuracy: 0.9649\n",
      "Epoch 165/500\n",
      "455/455 [==============================] - 0s 488us/sample - loss: 4.7459 - accuracy: 0.6923 - val_loss: 0.4189 - val_accuracy: 0.9649\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 652us/sample - loss: 5.2193 - accuracy: 0.6615 - val_loss: 0.4190 - val_accuracy: 0.9649\n",
      "Epoch 167/500\n",
      "455/455 [==============================] - 0s 687us/sample - loss: 5.0311 - accuracy: 0.6703 - val_loss: 0.5612 - val_accuracy: 0.9561\n",
      "Epoch 168/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 4.9161 - accuracy: 0.6813 - val_loss: 0.6990 - val_accuracy: 0.9474\n",
      "Epoch 169/500\n",
      "455/455 [==============================] - 0s 777us/sample - loss: 5.2536 - accuracy: 0.6593 - val_loss: 0.8124 - val_accuracy: 0.9474\n",
      "Epoch 170/500\n",
      "455/455 [==============================] - 0s 663us/sample - loss: 5.0506 - accuracy: 0.6725 - val_loss: 0.8121 - val_accuracy: 0.9474\n",
      "Epoch 171/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.4593 - accuracy: 0.6440 - val_loss: 0.8116 - val_accuracy: 0.9474\n",
      "Epoch 172/500\n",
      "455/455 [==============================] - 0s 584us/sample - loss: 5.1184 - accuracy: 0.6681 - val_loss: 0.8117 - val_accuracy: 0.9474\n",
      "Epoch 173/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.0587 - accuracy: 0.6681 - val_loss: 0.7170 - val_accuracy: 0.9474\n",
      "Epoch 174/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.4260 - accuracy: 0.6462 - val_loss: 0.6947 - val_accuracy: 0.9474\n",
      "Epoch 175/500\n",
      "455/455 [==============================] - 0s 549us/sample - loss: 5.4252 - accuracy: 0.6462 - val_loss: 0.5753 - val_accuracy: 0.9386\n",
      "Epoch 176/500\n",
      "455/455 [==============================] - 1s 1ms/sample - loss: 5.3897 - accuracy: 0.6505 - val_loss: 0.5697 - val_accuracy: 0.9386\n",
      "Epoch 177/500\n",
      "455/455 [==============================] - 1s 1ms/sample - loss: 4.7864 - accuracy: 0.6879 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 178/500\n",
      "455/455 [==============================] - 1s 1ms/sample - loss: 4.8525 - accuracy: 0.6835 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 179/500\n",
      "455/455 [==============================] - 0s 824us/sample - loss: 5.1858 - accuracy: 0.6637 - val_loss: 0.4193 - val_accuracy: 0.9649\n",
      "Epoch 180/500\n",
      "455/455 [==============================] - 0s 747us/sample - loss: 4.6787 - accuracy: 0.6967 - val_loss: 0.4136 - val_accuracy: 0.9649\n",
      "Epoch 181/500\n",
      "455/455 [==============================] - 0s 584us/sample - loss: 5.0233 - accuracy: 0.6703 - val_loss: 0.4080 - val_accuracy: 0.9737\n",
      "Epoch 182/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 4.5084 - accuracy: 0.7077 - val_loss: 0.4066 - val_accuracy: 0.9737\n",
      "Epoch 183/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 4.6957 - accuracy: 0.6901 - val_loss: 0.3024 - val_accuracy: 0.9649\n",
      "Epoch 184/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.8464 - accuracy: 0.6857 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 185/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.2573 - accuracy: 0.6571 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 186/500\n",
      "455/455 [==============================] - 0s 513us/sample - loss: 5.1938 - accuracy: 0.6571 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 187/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 5.2204 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 188/500\n",
      "455/455 [==============================] - 0s 656us/sample - loss: 5.0490 - accuracy: 0.6725 - val_loss: 0.4219 - val_accuracy: 0.9649\n",
      "Epoch 189/500\n",
      "455/455 [==============================] - 0s 687us/sample - loss: 5.1170 - accuracy: 0.6681 - val_loss: 0.4199 - val_accuracy: 0.9649\n",
      "Epoch 190/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 5.3310 - accuracy: 0.6505 - val_loss: 0.4084 - val_accuracy: 0.9737\n",
      "Epoch 191/500\n",
      "455/455 [==============================] - 0s 649us/sample - loss: 5.2609 - accuracy: 0.6571 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 192/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 4.9847 - accuracy: 0.6747 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 193/500\n",
      "455/455 [==============================] - 0s 549us/sample - loss: 4.5091 - accuracy: 0.7077 - val_loss: 0.4045 - val_accuracy: 0.9737\n",
      "Epoch 194/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 4.8842 - accuracy: 0.6813 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 195/500\n",
      "455/455 [==============================] - 0s 584us/sample - loss: 4.8809 - accuracy: 0.6835 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 196/500\n",
      "455/455 [==============================] - 0s 751us/sample - loss: 5.5600 - accuracy: 0.6396 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 197/500\n",
      "455/455 [==============================] - 0s 805us/sample - loss: 4.8809 - accuracy: 0.6835 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 198/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 4.9154 - accuracy: 0.6813 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 199/500\n",
      "455/455 [==============================] - 1s 1ms/sample - loss: 4.9500 - accuracy: 0.6791 - val_loss: 0.4053 - val_accuracy: 0.9737\n",
      "Epoch 200/500\n",
      "455/455 [==============================] - 0s 883us/sample - loss: 5.2221 - accuracy: 0.6593 - val_loss: 0.4046 - val_accuracy: 0.9737\n",
      "Epoch 201/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 4.6480 - accuracy: 0.6967 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 202/500\n",
      "455/455 [==============================] - 0s 515us/sample - loss: 4.5419 - accuracy: 0.7055 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 203/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3922 - accuracy: 0.6484 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 204/500\n",
      "455/455 [==============================] - 0s 479us/sample - loss: 5.3888 - accuracy: 0.6505 - val_loss: 0.4089 - val_accuracy: 0.9737\n",
      "Epoch 205/500\n",
      "455/455 [==============================] - 0s 453us/sample - loss: 4.7508 - accuracy: 0.6879 - val_loss: 0.4159 - val_accuracy: 0.9649\n",
      "Epoch 206/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.1190 - accuracy: 0.6681 - val_loss: 0.4245 - val_accuracy: 0.9649\n",
      "Epoch 207/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.1870 - accuracy: 0.6637 - val_loss: 0.4352 - val_accuracy: 0.9649\n",
      "Epoch 208/500\n",
      "455/455 [==============================] - 0s 610us/sample - loss: 4.7796 - accuracy: 0.6901 - val_loss: 0.4259 - val_accuracy: 0.9649\n",
      "Epoch 209/500\n",
      "455/455 [==============================] - 0s 837us/sample - loss: 5.1865 - accuracy: 0.6637 - val_loss: 0.4517 - val_accuracy: 0.9649\n",
      "Epoch 210/500\n",
      "455/455 [==============================] - 0s 652us/sample - loss: 4.9841 - accuracy: 0.6747 - val_loss: 0.4451 - val_accuracy: 0.9649\n",
      "Epoch 211/500\n",
      "455/455 [==============================] - 0s 961us/sample - loss: 5.0202 - accuracy: 0.6725 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 212/500\n",
      "455/455 [==============================] - 0s 707us/sample - loss: 5.0525 - accuracy: 0.6703 - val_loss: 0.5406 - val_accuracy: 0.9649\n",
      "Epoch 213/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.6231 - accuracy: 0.6989 - val_loss: 0.4209 - val_accuracy: 0.9561\n",
      "Epoch 214/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.6272 - accuracy: 0.6352 - val_loss: 1.0934 - val_accuracy: 0.9211\n",
      "Epoch 215/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.4577 - accuracy: 0.6462 - val_loss: 1.2449 - val_accuracy: 0.9035\n",
      "Epoch 216/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.5958 - accuracy: 0.6352 - val_loss: 1.3114 - val_accuracy: 0.9035\n",
      "Epoch 217/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.4606 - accuracy: 0.6440 - val_loss: 1.3735 - val_accuracy: 0.9035\n",
      "Epoch 218/500\n",
      "455/455 [==============================] - 0s 549us/sample - loss: 4.9556 - accuracy: 0.6747 - val_loss: 1.2662 - val_accuracy: 0.9035\n",
      "Epoch 219/500\n",
      "455/455 [==============================] - 0s 728us/sample - loss: 5.8374 - accuracy: 0.6198 - val_loss: 1.0978 - val_accuracy: 0.9298\n",
      "Epoch 220/500\n",
      "455/455 [==============================] - 0s 961us/sample - loss: 6.0708 - accuracy: 0.6044 - val_loss: 1.0927 - val_accuracy: 0.9298\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 824us/sample - loss: 5.9675 - accuracy: 0.6132 - val_loss: 0.9856 - val_accuracy: 0.9298\n",
      "Epoch 222/500\n",
      "455/455 [==============================] - 0s 749us/sample - loss: 5.3597 - accuracy: 0.6527 - val_loss: 0.9690 - val_accuracy: 0.9298\n",
      "Epoch 223/500\n",
      "455/455 [==============================] - 0s 617us/sample - loss: 5.2229 - accuracy: 0.6593 - val_loss: 0.9641 - val_accuracy: 0.9298\n",
      "Epoch 224/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.4960 - accuracy: 0.6396 - val_loss: 0.9581 - val_accuracy: 0.9298\n",
      "Epoch 225/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.3293 - accuracy: 0.6505 - val_loss: 0.9559 - val_accuracy: 0.9298\n",
      "Epoch 226/500\n",
      "455/455 [==============================] - 0s 436us/sample - loss: 5.1208 - accuracy: 0.6659 - val_loss: 0.8371 - val_accuracy: 0.9298\n",
      "Epoch 227/500\n",
      "455/455 [==============================] - 0s 465us/sample - loss: 5.5324 - accuracy: 0.6396 - val_loss: 0.8269 - val_accuracy: 0.9298\n",
      "Epoch 228/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 4.9159 - accuracy: 0.6813 - val_loss: 0.8221 - val_accuracy: 0.9386\n",
      "Epoch 229/500\n",
      "455/455 [==============================] - 0s 446us/sample - loss: 5.2988 - accuracy: 0.6527 - val_loss: 0.7038 - val_accuracy: 0.9474\n",
      "Epoch 230/500\n",
      "455/455 [==============================] - 0s 463us/sample - loss: 5.0182 - accuracy: 0.6747 - val_loss: 0.8222 - val_accuracy: 0.9386\n",
      "Epoch 231/500\n",
      "455/455 [==============================] - 0s 560us/sample - loss: 5.6293 - accuracy: 0.6330 - val_loss: 0.8184 - val_accuracy: 0.9474\n",
      "Epoch 232/500\n",
      "455/455 [==============================] - 0s 618us/sample - loss: 4.8144 - accuracy: 0.6879 - val_loss: 0.8153 - val_accuracy: 0.9474\n",
      "Epoch 233/500\n",
      "455/455 [==============================] - 0s 712us/sample - loss: 5.3216 - accuracy: 0.6549 - val_loss: 0.8152 - val_accuracy: 0.9474\n",
      "Epoch 234/500\n",
      "455/455 [==============================] - 0s 685us/sample - loss: 4.8815 - accuracy: 0.6835 - val_loss: 0.8152 - val_accuracy: 0.9474\n",
      "Epoch 235/500\n",
      "455/455 [==============================] - 0s 692us/sample - loss: 5.1346 - accuracy: 0.6615 - val_loss: 0.4457 - val_accuracy: 0.9474\n",
      "Epoch 236/500\n",
      "455/455 [==============================] - 0s 738us/sample - loss: 5.5663 - accuracy: 0.6374 - val_loss: 0.6814 - val_accuracy: 0.9474\n",
      "Epoch 237/500\n",
      "455/455 [==============================] - 0s 516us/sample - loss: 4.9158 - accuracy: 0.6813 - val_loss: 0.6860 - val_accuracy: 0.9474\n",
      "Epoch 238/500\n",
      "455/455 [==============================] - 0s 517us/sample - loss: 5.2714 - accuracy: 0.6549 - val_loss: 0.8099 - val_accuracy: 0.9474\n",
      "Epoch 239/500\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 6.0670 - accuracy: 0.6066 - val_loss: 1.2159 - val_accuracy: 0.9211\n",
      "Epoch 240/500\n",
      "455/455 [==============================] - 0s 637us/sample - loss: 5.0520 - accuracy: 0.6703 - val_loss: 1.2184 - val_accuracy: 0.9211\n",
      "Epoch 241/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 5.6642 - accuracy: 0.6286 - val_loss: 1.2129 - val_accuracy: 0.9211\n",
      "Epoch 242/500\n",
      "455/455 [==============================] - 0s 835us/sample - loss: 5.7030 - accuracy: 0.6264 - val_loss: 1.0799 - val_accuracy: 0.9298\n",
      "Epoch 243/500\n",
      "455/455 [==============================] - 0s 890us/sample - loss: 5.8279 - accuracy: 0.6220 - val_loss: 1.0776 - val_accuracy: 0.9298\n",
      "Epoch 244/500\n",
      "455/455 [==============================] - 0s 945us/sample - loss: 5.2515 - accuracy: 0.6593 - val_loss: 0.9585 - val_accuracy: 0.9298\n",
      "Epoch 245/500\n",
      "455/455 [==============================] - 0s 898us/sample - loss: 5.4582 - accuracy: 0.6440 - val_loss: 0.9519 - val_accuracy: 0.9298\n",
      "Epoch 246/500\n",
      "455/455 [==============================] - 0s 659us/sample - loss: 5.4587 - accuracy: 0.6440 - val_loss: 0.9524 - val_accuracy: 0.9298\n",
      "Epoch 247/500\n",
      "455/455 [==============================] - 0s 527us/sample - loss: 5.3566 - accuracy: 0.6505 - val_loss: 0.9479 - val_accuracy: 0.9386\n",
      "Epoch 248/500\n",
      "455/455 [==============================] - 0s 692us/sample - loss: 5.0827 - accuracy: 0.6703 - val_loss: 0.9452 - val_accuracy: 0.9386\n",
      "Epoch 249/500\n",
      "455/455 [==============================] - 0s 657us/sample - loss: 5.4552 - accuracy: 0.6462 - val_loss: 0.9454 - val_accuracy: 0.9386\n",
      "Epoch 250/500\n",
      "455/455 [==============================] - 0s 539us/sample - loss: 4.9245 - accuracy: 0.6747 - val_loss: 0.9446 - val_accuracy: 0.9386\n",
      "Epoch 251/500\n",
      "455/455 [==============================] - 0s 725us/sample - loss: 5.6915 - accuracy: 0.6308 - val_loss: 0.9436 - val_accuracy: 0.9386\n",
      "Epoch 252/500\n",
      "455/455 [==============================] - 0s 837us/sample - loss: 5.5920 - accuracy: 0.6374 - val_loss: 0.9435 - val_accuracy: 0.9386\n",
      "Epoch 253/500\n",
      "455/455 [==============================] - 0s 754us/sample - loss: 5.4561 - accuracy: 0.6462 - val_loss: 0.9440 - val_accuracy: 0.9386\n",
      "Epoch 254/500\n",
      "455/455 [==============================] - 0s 837us/sample - loss: 5.6259 - accuracy: 0.6352 - val_loss: 0.9439 - val_accuracy: 0.9386\n",
      "Epoch 255/500\n",
      "455/455 [==============================] - 0s 670us/sample - loss: 5.0311 - accuracy: 0.6703 - val_loss: 1.2340 - val_accuracy: 0.9123\n",
      "Epoch 256/500\n",
      "455/455 [==============================] - 0s 563us/sample - loss: 5.3571 - accuracy: 0.6505 - val_loss: 1.3724 - val_accuracy: 0.8947\n",
      "Epoch 257/500\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 6.0363 - accuracy: 0.6066 - val_loss: 1.3620 - val_accuracy: 0.9035\n",
      "Epoch 258/500\n",
      "455/455 [==============================] - 0s 693us/sample - loss: 5.5902 - accuracy: 0.6374 - val_loss: 1.3560 - val_accuracy: 0.9035\n",
      "Epoch 259/500\n",
      "455/455 [==============================] - 0s 574us/sample - loss: 5.9972 - accuracy: 0.6110 - val_loss: 1.3555 - val_accuracy: 0.9035\n",
      "Epoch 260/500\n",
      "455/455 [==============================] - 0s 557us/sample - loss: 5.7958 - accuracy: 0.6220 - val_loss: 1.3527 - val_accuracy: 0.9123\n",
      "Epoch 261/500\n",
      "455/455 [==============================] - 0s 785us/sample - loss: 5.2860 - accuracy: 0.6571 - val_loss: 1.3505 - val_accuracy: 0.9123\n",
      "Epoch 262/500\n",
      "455/455 [==============================] - 0s 754us/sample - loss: 5.7943 - accuracy: 0.6242 - val_loss: 1.3510 - val_accuracy: 0.9123\n",
      "Epoch 263/500\n",
      "455/455 [==============================] - 0s 716us/sample - loss: 5.9697 - accuracy: 0.6088 - val_loss: 1.3474 - val_accuracy: 0.9123\n",
      "Epoch 264/500\n",
      "455/455 [==============================] - 0s 843us/sample - loss: 5.1252 - accuracy: 0.6637 - val_loss: 1.2159 - val_accuracy: 0.9211\n",
      "Epoch 265/500\n",
      "455/455 [==============================] - 0s 658us/sample - loss: 6.0650 - accuracy: 0.6066 - val_loss: 1.0912 - val_accuracy: 0.9211\n",
      "Epoch 266/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 5.2531 - accuracy: 0.6593 - val_loss: 1.0854 - val_accuracy: 0.9211\n",
      "Epoch 267/500\n",
      "455/455 [==============================] - 0s 534us/sample - loss: 5.6920 - accuracy: 0.6308 - val_loss: 1.0831 - val_accuracy: 0.9298\n",
      "Epoch 268/500\n",
      "455/455 [==============================] - 0s 638us/sample - loss: 5.3910 - accuracy: 0.6484 - val_loss: 1.0810 - val_accuracy: 0.9298\n",
      "Epoch 269/500\n",
      "455/455 [==============================] - 0s 579us/sample - loss: 4.7812 - accuracy: 0.6879 - val_loss: 1.0776 - val_accuracy: 0.9298\n",
      "Epoch 270/500\n",
      "455/455 [==============================] - 0s 556us/sample - loss: 5.2564 - accuracy: 0.6571 - val_loss: 1.0776 - val_accuracy: 0.9298\n",
      "Epoch 271/500\n",
      "455/455 [==============================] - 0s 622us/sample - loss: 5.0198 - accuracy: 0.6725 - val_loss: 1.0776 - val_accuracy: 0.9298\n",
      "Epoch 272/500\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 6.0402 - accuracy: 0.6066 - val_loss: 1.0776 - val_accuracy: 0.9298\n",
      "Epoch 273/500\n",
      "455/455 [==============================] - 0s 715us/sample - loss: 5.0920 - accuracy: 0.6681 - val_loss: 0.8275 - val_accuracy: 0.9386\n",
      "Epoch 274/500\n",
      "455/455 [==============================] - 0s 691us/sample - loss: 5.3547 - accuracy: 0.6527 - val_loss: 0.6951 - val_accuracy: 0.9386\n",
      "Epoch 275/500\n",
      "455/455 [==============================] - 0s 771us/sample - loss: 4.7790 - accuracy: 0.6901 - val_loss: 0.6891 - val_accuracy: 0.9386\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 791us/sample - loss: 4.2707 - accuracy: 0.7231 - val_loss: 0.6917 - val_accuracy: 0.9386\n",
      "Epoch 277/500\n",
      "455/455 [==============================] - 0s 670us/sample - loss: 5.8381 - accuracy: 0.6154 - val_loss: 0.6828 - val_accuracy: 0.9561\n",
      "Epoch 278/500\n",
      "455/455 [==============================] - 0s 582us/sample - loss: 5.5579 - accuracy: 0.6396 - val_loss: 0.6763 - val_accuracy: 0.9561\n",
      "Epoch 279/500\n",
      "455/455 [==============================] - 0s 593us/sample - loss: 5.5240 - accuracy: 0.6418 - val_loss: 0.6771 - val_accuracy: 0.9561\n",
      "Epoch 280/500\n",
      "455/455 [==============================] - 0s 595us/sample - loss: 4.5462 - accuracy: 0.7011 - val_loss: 0.6040 - val_accuracy: 0.9561\n",
      "Epoch 281/500\n",
      "455/455 [==============================] - 0s 532us/sample - loss: 5.5921 - accuracy: 0.6374 - val_loss: 0.5541 - val_accuracy: 0.9561\n",
      "Epoch 282/500\n",
      "455/455 [==============================] - 0s 675us/sample - loss: 5.3558 - accuracy: 0.6527 - val_loss: 0.5503 - val_accuracy: 0.9561\n",
      "Epoch 283/500\n",
      "455/455 [==============================] - 0s 726us/sample - loss: 5.3918 - accuracy: 0.6484 - val_loss: 0.5472 - val_accuracy: 0.9561\n",
      "Epoch 284/500\n",
      "455/455 [==============================] - 0s 723us/sample - loss: 5.5928 - accuracy: 0.6374 - val_loss: 0.5468 - val_accuracy: 0.9561\n",
      "Epoch 285/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 4.8460 - accuracy: 0.6857 - val_loss: 0.5466 - val_accuracy: 0.9561\n",
      "Epoch 286/500\n",
      "455/455 [==============================] - 0s 669us/sample - loss: 5.3289 - accuracy: 0.6527 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 287/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 4.6504 - accuracy: 0.6945 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 288/500\n",
      "455/455 [==============================] - 0s 761us/sample - loss: 5.5608 - accuracy: 0.6374 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 289/500\n",
      "455/455 [==============================] - 0s 695us/sample - loss: 5.5584 - accuracy: 0.6396 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 290/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 5.4289 - accuracy: 0.6440 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 291/500\n",
      "455/455 [==============================] - 0s 679us/sample - loss: 5.1850 - accuracy: 0.6637 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 292/500\n",
      "455/455 [==============================] - 0s 520us/sample - loss: 5.0504 - accuracy: 0.6725 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 293/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 4.9138 - accuracy: 0.6813 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 294/500\n",
      "455/455 [==============================] - 0s 505us/sample - loss: 5.3901 - accuracy: 0.6505 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 295/500\n",
      "455/455 [==============================] - 0s 651us/sample - loss: 4.8829 - accuracy: 0.6835 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 296/500\n",
      "455/455 [==============================] - 0s 660us/sample - loss: 4.9481 - accuracy: 0.6791 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 297/500\n",
      "455/455 [==============================] - 0s 718us/sample - loss: 5.1852 - accuracy: 0.6637 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 298/500\n",
      "455/455 [==============================] - 0s 843us/sample - loss: 5.1885 - accuracy: 0.6615 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 299/500\n",
      "455/455 [==============================] - 0s 834us/sample - loss: 5.5672 - accuracy: 0.6330 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 300/500\n",
      "455/455 [==============================] - 0s 799us/sample - loss: 5.1195 - accuracy: 0.6681 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 301/500\n",
      "455/455 [==============================] - 0s 713us/sample - loss: 5.1546 - accuracy: 0.6637 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 302/500\n",
      "455/455 [==============================] - 0s 750us/sample - loss: 5.0157 - accuracy: 0.6747 - val_loss: 0.2874 - val_accuracy: 0.9737\n",
      "Epoch 303/500\n",
      "455/455 [==============================] - 0s 743us/sample - loss: 4.3750 - accuracy: 0.7143 - val_loss: 0.2853 - val_accuracy: 0.9737\n",
      "Epoch 304/500\n",
      "455/455 [==============================] - 0s 685us/sample - loss: 5.3921 - accuracy: 0.6484 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 305/500\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 4.4402 - accuracy: 0.7121 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 306/500\n",
      "455/455 [==============================] - 0s 680us/sample - loss: 4.8159 - accuracy: 0.6857 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 307/500\n",
      "455/455 [==============================] - 0s 508us/sample - loss: 5.2232 - accuracy: 0.6593 - val_loss: 0.2817 - val_accuracy: 0.9737\n",
      "Epoch 308/500\n",
      "455/455 [==============================] - 0s 490us/sample - loss: 4.9820 - accuracy: 0.6769 - val_loss: 0.2813 - val_accuracy: 0.9737\n",
      "Epoch 309/500\n",
      "455/455 [==============================] - 0s 488us/sample - loss: 5.1529 - accuracy: 0.6659 - val_loss: 0.2852 - val_accuracy: 0.9737\n",
      "Epoch 310/500\n",
      "455/455 [==============================] - 0s 485us/sample - loss: 5.0835 - accuracy: 0.6703 - val_loss: 0.2833 - val_accuracy: 0.9737\n",
      "Epoch 311/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 4.6093 - accuracy: 0.7011 - val_loss: 0.2883 - val_accuracy: 0.9737\n",
      "Epoch 312/500\n",
      "455/455 [==============================] - 0s 513us/sample - loss: 5.1886 - accuracy: 0.6615 - val_loss: 0.2836 - val_accuracy: 0.9737\n",
      "Epoch 313/500\n",
      "455/455 [==============================] - 0s 505us/sample - loss: 5.3212 - accuracy: 0.6549 - val_loss: 0.2876 - val_accuracy: 0.9737\n",
      "Epoch 314/500\n",
      "455/455 [==============================] - 0s 792us/sample - loss: 4.7492 - accuracy: 0.6901 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 315/500\n",
      "455/455 [==============================] - 0s 967us/sample - loss: 4.4743 - accuracy: 0.7099 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 316/500\n",
      "455/455 [==============================] - 0s 954us/sample - loss: 5.2201 - accuracy: 0.6615 - val_loss: 0.4035 - val_accuracy: 0.9737\n",
      "Epoch 317/500\n",
      "455/455 [==============================] - 0s 830us/sample - loss: 5.1282 - accuracy: 0.6659 - val_loss: 0.2752 - val_accuracy: 0.9737\n",
      "Epoch 318/500\n",
      "455/455 [==============================] - 0s 802us/sample - loss: 5.0847 - accuracy: 0.6703 - val_loss: 0.2792 - val_accuracy: 0.9737\n",
      "Epoch 319/500\n",
      "455/455 [==============================] - 0s 736us/sample - loss: 5.3235 - accuracy: 0.6527 - val_loss: 0.2795 - val_accuracy: 0.9737\n",
      "Epoch 320/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 5.0507 - accuracy: 0.6725 - val_loss: 0.2791 - val_accuracy: 0.9737\n",
      "Epoch 321/500\n",
      "455/455 [==============================] - 0s 693us/sample - loss: 4.5758 - accuracy: 0.7033 - val_loss: 0.2791 - val_accuracy: 0.9825\n",
      "Epoch 322/500\n",
      "455/455 [==============================] - 0s 582us/sample - loss: 5.2912 - accuracy: 0.6549 - val_loss: 0.2783 - val_accuracy: 0.9825\n",
      "Epoch 323/500\n",
      "455/455 [==============================] - 0s 506us/sample - loss: 4.6439 - accuracy: 0.6989 - val_loss: 0.2829 - val_accuracy: 0.9737\n",
      "Epoch 324/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 5.4589 - accuracy: 0.6462 - val_loss: 0.2808 - val_accuracy: 0.9737\n",
      "Epoch 325/500\n",
      "455/455 [==============================] - 0s 480us/sample - loss: 5.0500 - accuracy: 0.6725 - val_loss: 0.2810 - val_accuracy: 0.9737\n",
      "Epoch 326/500\n",
      "455/455 [==============================] - 0s 478us/sample - loss: 4.9506 - accuracy: 0.6769 - val_loss: 0.2814 - val_accuracy: 0.9737\n",
      "Epoch 327/500\n",
      "455/455 [==============================] - 0s 483us/sample - loss: 5.2937 - accuracy: 0.6527 - val_loss: 0.2849 - val_accuracy: 0.9737\n",
      "Epoch 328/500\n",
      "455/455 [==============================] - 0s 500us/sample - loss: 4.9487 - accuracy: 0.6791 - val_loss: 0.2848 - val_accuracy: 0.9737\n",
      "Epoch 329/500\n",
      "455/455 [==============================] - 0s 605us/sample - loss: 5.1521 - accuracy: 0.6659 - val_loss: 0.2845 - val_accuracy: 0.9737\n",
      "Epoch 330/500\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 4.7482 - accuracy: 0.6901 - val_loss: 0.2789 - val_accuracy: 0.9737\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 691us/sample - loss: 5.4286 - accuracy: 0.6462 - val_loss: 0.2715 - val_accuracy: 0.9825\n",
      "Epoch 332/500\n",
      "455/455 [==============================] - 0s 721us/sample - loss: 5.2877 - accuracy: 0.6571 - val_loss: 0.2690 - val_accuracy: 0.9825\n",
      "Epoch 333/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 4.8129 - accuracy: 0.6879 - val_loss: 0.2690 - val_accuracy: 0.9825\n",
      "Epoch 334/500\n",
      "455/455 [==============================] - 0s 715us/sample - loss: 5.1180 - accuracy: 0.6681 - val_loss: 0.2690 - val_accuracy: 0.9825\n",
      "Epoch 335/500\n",
      "455/455 [==============================] - 0s 670us/sample - loss: 4.6107 - accuracy: 0.7011 - val_loss: 0.2690 - val_accuracy: 0.9825\n",
      "Epoch 336/500\n",
      "455/455 [==============================] - 0s 631us/sample - loss: 5.0346 - accuracy: 0.6659 - val_loss: 0.2759 - val_accuracy: 0.9825\n",
      "Epoch 337/500\n",
      "455/455 [==============================] - 0s 552us/sample - loss: 5.1565 - accuracy: 0.6615 - val_loss: 0.2871 - val_accuracy: 0.9649\n",
      "Epoch 338/500\n",
      "455/455 [==============================] - 0s 562us/sample - loss: 4.8595 - accuracy: 0.6791 - val_loss: 0.4085 - val_accuracy: 0.9737\n",
      "Epoch 339/500\n",
      "455/455 [==============================] - 0s 570us/sample - loss: 4.8470 - accuracy: 0.6857 - val_loss: 0.4054 - val_accuracy: 0.9737\n",
      "Epoch 340/500\n",
      "455/455 [==============================] - 0s 713us/sample - loss: 5.1182 - accuracy: 0.6681 - val_loss: 0.4053 - val_accuracy: 0.9737\n",
      "Epoch 341/500\n",
      "455/455 [==============================] - 0s 671us/sample - loss: 5.4249 - accuracy: 0.6484 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 342/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 4.8208 - accuracy: 0.6857 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 343/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 5.2608 - accuracy: 0.6527 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 344/500\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 5.4573 - accuracy: 0.6462 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 345/500\n",
      "455/455 [==============================] - 0s 691us/sample - loss: 4.5421 - accuracy: 0.7055 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 346/500\n",
      "455/455 [==============================] - 0s 695us/sample - loss: 4.7459 - accuracy: 0.6923 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 347/500\n",
      "455/455 [==============================] - 0s 696us/sample - loss: 4.9862 - accuracy: 0.6747 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 348/500\n",
      "455/455 [==============================] - 0s 725us/sample - loss: 5.2249 - accuracy: 0.6593 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 349/500\n",
      "455/455 [==============================] - 0s 680us/sample - loss: 4.8824 - accuracy: 0.6835 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 350/500\n",
      "455/455 [==============================] - 0s 478us/sample - loss: 4.5828 - accuracy: 0.7011 - val_loss: 0.4043 - val_accuracy: 0.9737\n",
      "Epoch 351/500\n",
      "455/455 [==============================] - 0s 490us/sample - loss: 4.7799 - accuracy: 0.6901 - val_loss: 0.4107 - val_accuracy: 0.9649\n",
      "Epoch 352/500\n",
      "455/455 [==============================] - 0s 511us/sample - loss: 5.7630 - accuracy: 0.6264 - val_loss: 0.4131 - val_accuracy: 0.9649\n",
      "Epoch 353/500\n",
      "455/455 [==============================] - 0s 484us/sample - loss: 5.5251 - accuracy: 0.6418 - val_loss: 0.4126 - val_accuracy: 0.9649\n",
      "Epoch 354/500\n",
      "455/455 [==============================] - 0s 631us/sample - loss: 5.2540 - accuracy: 0.6593 - val_loss: 0.4121 - val_accuracy: 0.9649\n",
      "Epoch 355/500\n",
      "455/455 [==============================] - 0s 646us/sample - loss: 5.0539 - accuracy: 0.6703 - val_loss: 0.4115 - val_accuracy: 0.9649\n",
      "Epoch 356/500\n",
      "455/455 [==============================] - 0s 883us/sample - loss: 4.6438 - accuracy: 0.6989 - val_loss: 0.4127 - val_accuracy: 0.9649\n",
      "Epoch 357/500\n",
      "455/455 [==============================] - 0s 793us/sample - loss: 5.1202 - accuracy: 0.6659 - val_loss: 0.4205 - val_accuracy: 0.9649\n",
      "Epoch 358/500\n",
      "455/455 [==============================] - 0s 791us/sample - loss: 5.1214 - accuracy: 0.6659 - val_loss: 0.4169 - val_accuracy: 0.9649\n",
      "Epoch 359/500\n",
      "455/455 [==============================] - 0s 687us/sample - loss: 4.5148 - accuracy: 0.7033 - val_loss: 0.4148 - val_accuracy: 0.9649\n",
      "Epoch 360/500\n",
      "455/455 [==============================] - 0s 622us/sample - loss: 5.5596 - accuracy: 0.6396 - val_loss: 0.4135 - val_accuracy: 0.9649\n",
      "Epoch 361/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.4238 - accuracy: 0.6484 - val_loss: 0.4138 - val_accuracy: 0.9649\n",
      "Epoch 362/500\n",
      "455/455 [==============================] - 0s 483us/sample - loss: 5.1538 - accuracy: 0.6659 - val_loss: 0.4153 - val_accuracy: 0.9649\n",
      "Epoch 363/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.6281 - accuracy: 0.6330 - val_loss: 0.4117 - val_accuracy: 0.9649\n",
      "Epoch 364/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.1186 - accuracy: 0.6681 - val_loss: 0.4096 - val_accuracy: 0.9737\n",
      "Epoch 365/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 4.9512 - accuracy: 0.6769 - val_loss: 0.4103 - val_accuracy: 0.9737\n",
      "Epoch 366/500\n",
      "455/455 [==============================] - 0s 486us/sample - loss: 5.0165 - accuracy: 0.6747 - val_loss: 0.4116 - val_accuracy: 0.9649\n",
      "Epoch 367/500\n",
      "455/455 [==============================] - 0s 553us/sample - loss: 5.1898 - accuracy: 0.6615 - val_loss: 0.4204 - val_accuracy: 0.9649\n",
      "Epoch 368/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 5.6626 - accuracy: 0.6330 - val_loss: 0.5396 - val_accuracy: 0.9649\n",
      "Epoch 369/500\n",
      "455/455 [==============================] - 0s 747us/sample - loss: 4.5083 - accuracy: 0.7077 - val_loss: 0.4232 - val_accuracy: 0.9649\n",
      "Epoch 370/500\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 4.9493 - accuracy: 0.6791 - val_loss: 0.4237 - val_accuracy: 0.9649\n",
      "Epoch 371/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 4.9493 - accuracy: 0.6791 - val_loss: 0.4257 - val_accuracy: 0.9649\n",
      "Epoch 372/500\n",
      "455/455 [==============================] - 0s 649us/sample - loss: 5.0925 - accuracy: 0.6681 - val_loss: 0.4057 - val_accuracy: 0.9737\n",
      "Epoch 373/500\n",
      "455/455 [==============================] - 0s 566us/sample - loss: 5.0163 - accuracy: 0.6747 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 374/500\n",
      "455/455 [==============================] - 0s 630us/sample - loss: 4.8488 - accuracy: 0.6857 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 375/500\n",
      "455/455 [==============================] - 0s 662us/sample - loss: 4.9824 - accuracy: 0.6769 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 376/500\n",
      "455/455 [==============================] - 0s 597us/sample - loss: 4.5770 - accuracy: 0.7033 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 377/500\n",
      "455/455 [==============================] - 0s 535us/sample - loss: 5.1887 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 378/500\n",
      "455/455 [==============================] - 0s 719us/sample - loss: 4.8131 - accuracy: 0.6879 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 379/500\n",
      "455/455 [==============================] - 0s 778us/sample - loss: 5.1180 - accuracy: 0.6681 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 380/500\n",
      "455/455 [==============================] - 0s 708us/sample - loss: 5.1564 - accuracy: 0.6637 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 381/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 5.0532 - accuracy: 0.6703 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 382/500\n",
      "455/455 [==============================] - 0s 706us/sample - loss: 4.4751 - accuracy: 0.7099 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 383/500\n",
      "455/455 [==============================] - 0s 691us/sample - loss: 5.4575 - accuracy: 0.6462 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 384/500\n",
      "455/455 [==============================] - 0s 707us/sample - loss: 5.1527 - accuracy: 0.6659 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 385/500\n",
      "455/455 [==============================] - 0s 687us/sample - loss: 4.5764 - accuracy: 0.7033 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 703us/sample - loss: 5.0509 - accuracy: 0.6725 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 387/500\n",
      "455/455 [==============================] - 0s 675us/sample - loss: 5.0529 - accuracy: 0.6703 - val_loss: 0.4147 - val_accuracy: 0.9649\n",
      "Epoch 388/500\n",
      "455/455 [==============================] - 0s 479us/sample - loss: 5.0861 - accuracy: 0.6703 - val_loss: 0.4107 - val_accuracy: 0.9649\n",
      "Epoch 389/500\n",
      "455/455 [==============================] - 0s 473us/sample - loss: 4.9148 - accuracy: 0.6813 - val_loss: 0.4088 - val_accuracy: 0.9737\n",
      "Epoch 390/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 5.2877 - accuracy: 0.6571 - val_loss: 0.4096 - val_accuracy: 0.9737\n",
      "Epoch 391/500\n",
      "455/455 [==============================] - 0s 474us/sample - loss: 4.9485 - accuracy: 0.6791 - val_loss: 0.4091 - val_accuracy: 0.9737\n",
      "Epoch 392/500\n",
      "455/455 [==============================] - 0s 496us/sample - loss: 4.9489 - accuracy: 0.6791 - val_loss: 0.4105 - val_accuracy: 0.9649\n",
      "Epoch 393/500\n",
      "455/455 [==============================] - 0s 485us/sample - loss: 4.9497 - accuracy: 0.6791 - val_loss: 0.4098 - val_accuracy: 0.9737\n",
      "Epoch 394/500\n",
      "455/455 [==============================] - 0s 694us/sample - loss: 4.7463 - accuracy: 0.6923 - val_loss: 0.4125 - val_accuracy: 0.9649\n",
      "Epoch 395/500\n",
      "455/455 [==============================] - 0s 941us/sample - loss: 4.6452 - accuracy: 0.6989 - val_loss: 0.4154 - val_accuracy: 0.9649\n",
      "Epoch 396/500\n",
      "455/455 [==============================] - 0s 972us/sample - loss: 4.9221 - accuracy: 0.6791 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 397/500\n",
      "455/455 [==============================] - 0s 787us/sample - loss: 4.7488 - accuracy: 0.6923 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 398/500\n",
      "455/455 [==============================] - 0s 812us/sample - loss: 5.2202 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 399/500\n",
      "455/455 [==============================] - 0s 725us/sample - loss: 5.1860 - accuracy: 0.6637 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 400/500\n",
      "455/455 [==============================] - 0s 695us/sample - loss: 5.0863 - accuracy: 0.6681 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 401/500\n",
      "455/455 [==============================] - 0s 706us/sample - loss: 5.1188 - accuracy: 0.6681 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 402/500\n",
      "455/455 [==============================] - 0s 685us/sample - loss: 4.7453 - accuracy: 0.6923 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 403/500\n",
      "455/455 [==============================] - 0s 588us/sample - loss: 4.9526 - accuracy: 0.6769 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 404/500\n",
      "455/455 [==============================] - 0s 487us/sample - loss: 5.0163 - accuracy: 0.6747 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 405/500\n",
      "455/455 [==============================] - 0s 499us/sample - loss: 5.2201 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 406/500\n",
      "455/455 [==============================] - 0s 508us/sample - loss: 5.4908 - accuracy: 0.6440 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 407/500\n",
      "455/455 [==============================] - 0s 543us/sample - loss: 4.7827 - accuracy: 0.6879 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 408/500\n",
      "455/455 [==============================] - 0s 556us/sample - loss: 4.8186 - accuracy: 0.6835 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 409/500\n",
      "455/455 [==============================] - 0s 567us/sample - loss: 5.1271 - accuracy: 0.6659 - val_loss: 0.5514 - val_accuracy: 0.9561\n",
      "Epoch 410/500\n",
      "455/455 [==============================] - 0s 780us/sample - loss: 5.1895 - accuracy: 0.6593 - val_loss: 0.8126 - val_accuracy: 0.9474\n",
      "Epoch 411/500\n",
      "455/455 [==============================] - 0s 710us/sample - loss: 5.1519 - accuracy: 0.6659 - val_loss: 0.8124 - val_accuracy: 0.9474\n",
      "Epoch 412/500\n",
      "455/455 [==============================] - 0s 704us/sample - loss: 5.3550 - accuracy: 0.6527 - val_loss: 0.8106 - val_accuracy: 0.9474\n",
      "Epoch 413/500\n",
      "455/455 [==============================] - 0s 850us/sample - loss: 5.1511 - accuracy: 0.6659 - val_loss: 0.8100 - val_accuracy: 0.9474\n",
      "Epoch 414/500\n",
      "455/455 [==============================] - 0s 945us/sample - loss: 5.3880 - accuracy: 0.6505 - val_loss: 0.8100 - val_accuracy: 0.9474\n",
      "Epoch 415/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.0852 - accuracy: 0.6681 - val_loss: 0.8105 - val_accuracy: 0.9474\n",
      "Epoch 416/500\n",
      "455/455 [==============================] - 0s 813us/sample - loss: 5.3884 - accuracy: 0.6505 - val_loss: 0.8109 - val_accuracy: 0.9474\n",
      "Epoch 417/500\n",
      "455/455 [==============================] - 0s 780us/sample - loss: 5.1539 - accuracy: 0.6637 - val_loss: 0.8079 - val_accuracy: 0.9474\n",
      "Epoch 418/500\n",
      "455/455 [==============================] - 0s 561us/sample - loss: 5.2865 - accuracy: 0.6571 - val_loss: 0.8078 - val_accuracy: 0.9474\n",
      "Epoch 419/500\n",
      "455/455 [==============================] - 0s 485us/sample - loss: 4.7780 - accuracy: 0.6901 - val_loss: 0.6943 - val_accuracy: 0.9474\n",
      "Epoch 420/500\n",
      "455/455 [==============================] - 0s 491us/sample - loss: 5.4903 - accuracy: 0.6440 - val_loss: 0.6883 - val_accuracy: 0.9474\n",
      "Epoch 421/500\n",
      "455/455 [==============================] - 0s 486us/sample - loss: 4.8860 - accuracy: 0.6813 - val_loss: 0.5432 - val_accuracy: 0.9649\n",
      "Epoch 422/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 4.8119 - accuracy: 0.6879 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 423/500\n",
      "455/455 [==============================] - 0s 488us/sample - loss: 5.4897 - accuracy: 0.6440 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 424/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.1854 - accuracy: 0.6637 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 425/500\n",
      "455/455 [==============================] - 0s 483us/sample - loss: 5.4223 - accuracy: 0.6484 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 426/500\n",
      "455/455 [==============================] - 0s 483us/sample - loss: 5.2197 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 427/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 4.9819 - accuracy: 0.6769 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 428/500\n",
      "455/455 [==============================] - 0s 496us/sample - loss: 5.4578 - accuracy: 0.6462 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 429/500\n",
      "455/455 [==============================] - 0s 481us/sample - loss: 5.4227 - accuracy: 0.6484 - val_loss: 0.5424 - val_accuracy: 0.9649\n",
      "Epoch 430/500\n",
      "455/455 [==============================] - 0s 483us/sample - loss: 5.1198 - accuracy: 0.6659 - val_loss: 0.5467 - val_accuracy: 0.9561\n",
      "Epoch 431/500\n",
      "455/455 [==============================] - 0s 490us/sample - loss: 5.6635 - accuracy: 0.6308 - val_loss: 0.5414 - val_accuracy: 0.9649\n",
      "Epoch 432/500\n",
      "455/455 [==============================] - 0s 659us/sample - loss: 5.0215 - accuracy: 0.6725 - val_loss: 0.5404 - val_accuracy: 0.9649\n",
      "Epoch 433/500\n",
      "455/455 [==============================] - 0s 709us/sample - loss: 5.1861 - accuracy: 0.6637 - val_loss: 0.5405 - val_accuracy: 0.9649\n",
      "Epoch 434/500\n",
      "455/455 [==============================] - 0s 742us/sample - loss: 4.9531 - accuracy: 0.6769 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 435/500\n",
      "455/455 [==============================] - 0s 979us/sample - loss: 4.9165 - accuracy: 0.6813 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 436/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.2925 - accuracy: 0.6549 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 437/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.1860 - accuracy: 0.6637 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 438/500\n",
      "455/455 [==============================] - 0s 867us/sample - loss: 5.3220 - accuracy: 0.6549 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 439/500\n",
      "455/455 [==============================] - 0s 767us/sample - loss: 4.8521 - accuracy: 0.6813 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 440/500\n",
      "455/455 [==============================] - 0s 676us/sample - loss: 4.8811 - accuracy: 0.6835 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 686us/sample - loss: 4.9836 - accuracy: 0.6769 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 442/500\n",
      "455/455 [==============================] - 0s 689us/sample - loss: 5.2877 - accuracy: 0.6571 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 443/500\n",
      "455/455 [==============================] - 0s 706us/sample - loss: 4.6095 - accuracy: 0.7011 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 444/500\n",
      "455/455 [==============================] - 0s 679us/sample - loss: 5.0504 - accuracy: 0.6725 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 445/500\n",
      "455/455 [==============================] - 0s 564us/sample - loss: 4.7827 - accuracy: 0.6879 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 446/500\n",
      "455/455 [==============================] - 0s 490us/sample - loss: 4.8805 - accuracy: 0.6835 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 447/500\n",
      "455/455 [==============================] - 0s 500us/sample - loss: 5.4300 - accuracy: 0.6462 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 448/500\n",
      "455/455 [==============================] - 0s 477us/sample - loss: 5.0845 - accuracy: 0.6703 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 449/500\n",
      "455/455 [==============================] - 0s 496us/sample - loss: 5.3236 - accuracy: 0.6527 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 450/500\n",
      "455/455 [==============================] - 0s 517us/sample - loss: 5.0833 - accuracy: 0.6703 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 451/500\n",
      "455/455 [==============================] - 0s 528us/sample - loss: 4.8805 - accuracy: 0.6835 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 452/500\n",
      "455/455 [==============================] - 0s 717us/sample - loss: 4.9181 - accuracy: 0.6791 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 453/500\n",
      "455/455 [==============================] - 0s 765us/sample - loss: 4.9169 - accuracy: 0.6791 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 454/500\n",
      "455/455 [==============================] - 0s 807us/sample - loss: 5.3254 - accuracy: 0.6527 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 455/500\n",
      "455/455 [==============================] - 0s 945us/sample - loss: 5.4910 - accuracy: 0.6440 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 456/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 5.2877 - accuracy: 0.6571 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 457/500\n",
      "455/455 [==============================] - 0s 829us/sample - loss: 4.7142 - accuracy: 0.6945 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 458/500\n",
      "455/455 [==============================] - 0s 793us/sample - loss: 5.0502 - accuracy: 0.6725 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 459/500\n",
      "455/455 [==============================] - 0s 696us/sample - loss: 5.6607 - accuracy: 0.6330 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 460/500\n",
      "455/455 [==============================] - 0s 592us/sample - loss: 5.0244 - accuracy: 0.6725 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 461/500\n",
      "455/455 [==============================] - 0s 484us/sample - loss: 4.5450 - accuracy: 0.7055 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 462/500\n",
      "455/455 [==============================] - 0s 484us/sample - loss: 5.0521 - accuracy: 0.6703 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 463/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.3219 - accuracy: 0.6549 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 464/500\n",
      "455/455 [==============================] - 0s 495us/sample - loss: 5.0167 - accuracy: 0.6747 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 465/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 5.3214 - accuracy: 0.6549 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 466/500\n",
      "455/455 [==============================] - 0s 484us/sample - loss: 5.1866 - accuracy: 0.6637 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 467/500\n",
      "455/455 [==============================] - 0s 556us/sample - loss: 5.0845 - accuracy: 0.6703 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 468/500\n",
      "455/455 [==============================] - 0s 697us/sample - loss: 4.8127 - accuracy: 0.6879 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 469/500\n",
      "455/455 [==============================] - 0s 713us/sample - loss: 5.2886 - accuracy: 0.6571 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 470/500\n",
      "455/455 [==============================] - 0s 707us/sample - loss: 5.3555 - accuracy: 0.6527 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 471/500\n",
      "455/455 [==============================] - 0s 698us/sample - loss: 5.2207 - accuracy: 0.6615 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 472/500\n",
      "455/455 [==============================] - 0s 621us/sample - loss: 5.6970 - accuracy: 0.6286 - val_loss: 0.5388 - val_accuracy: 0.9649\n",
      "Epoch 473/500\n",
      "455/455 [==============================] - 0s 494us/sample - loss: 4.8852 - accuracy: 0.6813 - val_loss: 0.4202 - val_accuracy: 0.9649\n",
      "Epoch 474/500\n",
      "455/455 [==============================] - 0s 476us/sample - loss: 4.9830 - accuracy: 0.6769 - val_loss: 0.4130 - val_accuracy: 0.9649\n",
      "Epoch 475/500\n",
      "455/455 [==============================] - 0s 650us/sample - loss: 5.3573 - accuracy: 0.6527 - val_loss: 0.4114 - val_accuracy: 0.9649\n",
      "Epoch 476/500\n",
      "455/455 [==============================] - 0s 649us/sample - loss: 4.9157 - accuracy: 0.6813 - val_loss: 0.4081 - val_accuracy: 0.9737\n",
      "Epoch 477/500\n",
      "455/455 [==============================] - 0s 654us/sample - loss: 4.4406 - accuracy: 0.7121 - val_loss: 0.4070 - val_accuracy: 0.9737\n",
      "Epoch 478/500\n",
      "455/455 [==============================] - 0s 713us/sample - loss: 5.1521 - accuracy: 0.6659 - val_loss: 0.4070 - val_accuracy: 0.9737\n",
      "Epoch 479/500\n",
      "455/455 [==============================] - 0s 792us/sample - loss: 5.2208 - accuracy: 0.6615 - val_loss: 0.4075 - val_accuracy: 0.9737\n",
      "Epoch 480/500\n",
      "455/455 [==============================] - 0s 726us/sample - loss: 5.0526 - accuracy: 0.6703 - val_loss: 0.4072 - val_accuracy: 0.9737\n",
      "Epoch 481/500\n",
      "455/455 [==============================] - 0s 675us/sample - loss: 5.2884 - accuracy: 0.6571 - val_loss: 0.4081 - val_accuracy: 0.9737\n",
      "Epoch 482/500\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 4.6198 - accuracy: 0.6989 - val_loss: 0.6749 - val_accuracy: 0.9561\n",
      "Epoch 483/500\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 4.9845 - accuracy: 0.6747 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 484/500\n",
      "455/455 [==============================] - 0s 682us/sample - loss: 5.2547 - accuracy: 0.6593 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 485/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 5.1522 - accuracy: 0.6659 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 486/500\n",
      "455/455 [==============================] - 0s 703us/sample - loss: 5.3912 - accuracy: 0.6484 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 487/500\n",
      "455/455 [==============================] - 0s 710us/sample - loss: 5.3892 - accuracy: 0.6505 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 488/500\n",
      "455/455 [==============================] - 0s 676us/sample - loss: 4.8134 - accuracy: 0.6879 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 489/500\n",
      "455/455 [==============================] - 0s 681us/sample - loss: 4.9150 - accuracy: 0.6813 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 490/500\n",
      "455/455 [==============================] - 0s 678us/sample - loss: 5.2576 - accuracy: 0.6549 - val_loss: 0.8086 - val_accuracy: 0.9474\n",
      "Epoch 491/500\n",
      "455/455 [==============================] - 0s 702us/sample - loss: 4.4104 - accuracy: 0.7121 - val_loss: 0.6869 - val_accuracy: 0.9474\n",
      "Epoch 492/500\n",
      "455/455 [==============================] - 0s 686us/sample - loss: 4.9150 - accuracy: 0.6813 - val_loss: 0.6789 - val_accuracy: 0.9561\n",
      "Epoch 493/500\n",
      "455/455 [==============================] - 0s 951us/sample - loss: 5.4568 - accuracy: 0.6462 - val_loss: 0.6781 - val_accuracy: 0.9561\n",
      "Epoch 494/500\n",
      "455/455 [==============================] - 0s 1ms/sample - loss: 4.7453 - accuracy: 0.6923 - val_loss: 0.6774 - val_accuracy: 0.9561\n",
      "Epoch 495/500\n",
      "455/455 [==============================] - 0s 960us/sample - loss: 4.9869 - accuracy: 0.6747 - val_loss: 0.6744 - val_accuracy: 0.9561\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 708us/sample - loss: 5.2230 - accuracy: 0.6593 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 497/500\n",
      "455/455 [==============================] - 0s 533us/sample - loss: 5.0839 - accuracy: 0.6703 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 498/500\n",
      "455/455 [==============================] - 0s 505us/sample - loss: 5.4653 - accuracy: 0.6418 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 499/500\n",
      "455/455 [==============================] - 0s 478us/sample - loss: 4.8823 - accuracy: 0.6835 - val_loss: 0.6741 - val_accuracy: 0.9561\n",
      "Epoch 500/500\n",
      "455/455 [==============================] - 0s 479us/sample - loss: 4.7455 - accuracy: 0.6923 - val_loss: 0.6741 - val_accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
